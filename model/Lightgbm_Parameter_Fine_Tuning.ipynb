{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from itertools import product\n",
    "\n",
    "# my module\n",
    "from conf.configure import Configure\n",
    "from utils import data_utils, dataframe_util\n",
    "from utils.common_utils import common_num_range\n",
    "\n",
    "import model.get_datasets as gd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 40307, test: 10076, feature count: 368, orderType 1:0 = 0.16436\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(Configure.base_path + 'huang_lin/train_dataHL.csv')\n",
    "test = pd.read_csv(Configure.base_path + 'huang_lin/test_dataHL.csv')\n",
    "\n",
    "y_train = train['orderType']\n",
    "train.drop(['orderType'], axis=1, inplace=True)\n",
    "\n",
    "df_columns = train.columns.values\n",
    "print('train: {}, test: {}, feature count: {}, orderType 1:0 = {:.5f}'.format(\n",
    "    train.shape[0], test.shape[0], len(df_columns), 1.0*sum(y_train) / len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = lgbm.Dataset(train, label=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from itertools import product\n",
    "\n",
    "def model_cross_validate(model_params, cv_param_dict, dtrain, cv_num_boost_round=4000, early_stopping_rounds=100, cv_nfold=5, stratified=True):\n",
    "    params_value = []\n",
    "    params_name = cv_param_dict.keys()\n",
    "    max_auc = 0\n",
    "    for param in params_name:\n",
    "        params_value.append(cv_param_dict[param])\n",
    "\n",
    "    for param_pair in product(*params_value):\n",
    "        param_str = ''\n",
    "        for i in xrange(len(param_pair)):\n",
    "            param_str += params_name[i] + '=' + str(param_pair[i]) + ' '\n",
    "            model_params[params_name[i]] = param_pair[i]\n",
    "        \n",
    "        start = time.time()\n",
    "        cv_result = lgbm.cv(model_params, dtrain, num_boost_round=cv_num_boost_round, stratified=stratified,\n",
    "                           nfold=cv_nfold, early_stopping_rounds=early_stopping_rounds)\n",
    "        \n",
    "        best_num_boost_rounds = len(cv_result['auc-mean'])\n",
    "        mean_test_auc = np.mean(cv_result['auc-mean'][best_num_boost_rounds-6 : best_num_boost_rounds-1])\n",
    "        if mean_test_auc > max_auc:\n",
    "            best_param = param_pair\n",
    "            max_auc = mean_test_auc\n",
    "        \n",
    "        end = time.time()\n",
    "        print('{}, best_ntree_limit:{}, auc = {:.7f}, cost: {}s'.format(param_str, best_num_boost_rounds,\n",
    "                                                                              mean_test_auc, end-start))\n",
    "    param_str = ''\n",
    "    for i in xrange(len(best_param)):\n",
    "        param_str += params_name[i] + '=' + str(best_param[i]) + ' '\n",
    "        model_params[params_name[i]] = best_param[i]\n",
    "    print('===========best paramter: {} auc={:.7f}==========='.format(param_str, max_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Fix learning rate and number of estimators for tuning tree-based parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'min_split_gain': 0,\n",
    "        'min_child_weight': 4,\n",
    "        'learning_rate': 0.1,\n",
    "        'num_leaves': 64,\n",
    "        'min_sum_hessian_in_leaf': 0.1,\n",
    "        'feature_fraction': 0.5,\n",
    "        'feature_fraction_seed': 10,\n",
    "        'bagging_fraction': 0.6,\n",
    "        'bagging_seed': 10,\n",
    "        'lambda_l1': 0.5,\n",
    "        'lambda_l2': 0.5,\n",
    "        'num_thread': -1,\n",
    "        'verbose': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> calc baseline model\n",
      "mean_test_auc = 0.9717915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---> calc baseline model')\n",
    "\n",
    "cv_num_boost_round=4000\n",
    "early_stopping_rounds=100\n",
    "cv_nfold=5\n",
    "stratified=True\n",
    "\n",
    "cv_result = lgbm.cv(lgbm_params,\n",
    "                    dtrain,\n",
    "                    nfold=cv_nfold,\n",
    "                    stratified=stratified,\n",
    "                    num_boost_round=cv_num_boost_round,\n",
    "                    early_stopping_rounds=early_stopping_rounds,\n",
    "                    )\n",
    "best_num_boost_rounds = len(cv_result['auc-mean'])\n",
    "mean_test_auc = np.mean(cv_result['auc-mean'][best_num_boost_rounds-6 : best_num_boost_rounds-1])\n",
    "\n",
    "print('mean_test_auc = {:.7f}\\n'.format(mean_test_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune *num_leaves* and *min_child_weight*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_leaves=32 , best_ntree_limit:306, auc = 0.9707847, cost: 28.4157309532s\n",
      "num_leaves=64 , best_ntree_limit:441, auc = 0.9717915, cost: 60.2170989513s\n",
      "num_leaves=128 , best_ntree_limit:305, auc = 0.9710133, cost: 68.8745148182s\n",
      "===========best paramter: num_leaves=64  auc=0.9717915===========\n"
     ]
    }
   ],
   "source": [
    "cv_paramters = {'num_leaves':[2**5, 2**6, 2**7]}\n",
    "model_cross_validate(lgbm_params, cv_paramters, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune bagging_fraction and feature_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging_fraction=0.5 feature_fraction=0.5 , best_ntree_limit:441, auc = 0.9717915, cost: 60.1709551811s\n",
      "bagging_fraction=0.5 feature_fraction=0.6 , best_ntree_limit:494, auc = 0.9713985, cost: 68.082005024s\n",
      "bagging_fraction=0.5 feature_fraction=0.7 , best_ntree_limit:436, auc = 0.9716777, cost: 64.8330609798s\n",
      "bagging_fraction=0.5 feature_fraction=0.8 , best_ntree_limit:400, auc = 0.9715962, cost: 63.5356798172s\n",
      "bagging_fraction=0.5 feature_fraction=0.9 , best_ntree_limit:342, auc = 0.9711587, cost: 59.5559711456s\n",
      "bagging_fraction=0.5 feature_fraction=1.0 , best_ntree_limit:476, auc = 0.9714961, cost: 76.5802919865s\n",
      "bagging_fraction=0.6 feature_fraction=0.5 , best_ntree_limit:441, auc = 0.9717915, cost: 59.8302419186s\n",
      "bagging_fraction=0.6 feature_fraction=0.6 , best_ntree_limit:494, auc = 0.9713985, cost: 68.1966850758s\n",
      "bagging_fraction=0.6 feature_fraction=0.7 , best_ntree_limit:436, auc = 0.9716777, cost: 64.6554200649s\n",
      "bagging_fraction=0.6 feature_fraction=0.8 , best_ntree_limit:400, auc = 0.9715962, cost: 63.4784030914s\n",
      "bagging_fraction=0.6 feature_fraction=0.9 , best_ntree_limit:342, auc = 0.9711587, cost: 59.1726140976s\n",
      "bagging_fraction=0.6 feature_fraction=1.0 , best_ntree_limit:476, auc = 0.9714961, cost: 76.7140431404s\n",
      "bagging_fraction=0.7 feature_fraction=0.5 , best_ntree_limit:441, auc = 0.9717915, cost: 60.1563410759s\n",
      "bagging_fraction=0.7 feature_fraction=0.6 , best_ntree_limit:494, auc = 0.9713985, cost: 67.996199131s\n",
      "bagging_fraction=0.7 feature_fraction=0.7 , best_ntree_limit:436, auc = 0.9716777, cost: 64.978497982s\n",
      "bagging_fraction=0.7 feature_fraction=0.8 , best_ntree_limit:400, auc = 0.9715962, cost: 63.6237299442s\n",
      "bagging_fraction=0.7 feature_fraction=0.9 , best_ntree_limit:342, auc = 0.9711587, cost: 59.6516261101s\n",
      "bagging_fraction=0.7 feature_fraction=1.0 , best_ntree_limit:476, auc = 0.9714961, cost: 76.1279809475s\n",
      "bagging_fraction=0.8 feature_fraction=0.5 , best_ntree_limit:441, auc = 0.9717915, cost: 60.3811612129s\n",
      "bagging_fraction=0.8 feature_fraction=0.6 , best_ntree_limit:494, auc = 0.9713985, cost: 67.6403529644s\n",
      "bagging_fraction=0.8 feature_fraction=0.7 , best_ntree_limit:436, auc = 0.9716777, cost: 63.6667289734s\n",
      "bagging_fraction=0.8 feature_fraction=0.8 , best_ntree_limit:400, auc = 0.9715962, cost: 75.4425430298s\n",
      "bagging_fraction=0.8 feature_fraction=0.9 , best_ntree_limit:342, auc = 0.9711587, cost: 59.0690808296s\n",
      "bagging_fraction=0.8 feature_fraction=1.0 , best_ntree_limit:476, auc = 0.9714961, cost: 75.9568190575s\n",
      "bagging_fraction=0.9 feature_fraction=0.5 , best_ntree_limit:441, auc = 0.9717915, cost: 59.458108902s\n",
      "bagging_fraction=0.9 feature_fraction=0.6 , best_ntree_limit:494, auc = 0.9713985, cost: 67.2252810001s\n",
      "bagging_fraction=0.9 feature_fraction=0.7 , best_ntree_limit:436, auc = 0.9716777, cost: 64.1664299965s\n",
      "bagging_fraction=0.9 feature_fraction=0.8 , best_ntree_limit:400, auc = 0.9715962, cost: 62.8515300751s\n",
      "bagging_fraction=0.9 feature_fraction=0.9 , best_ntree_limit:342, auc = 0.9711587, cost: 58.7432730198s\n",
      "bagging_fraction=0.9 feature_fraction=1.0 , best_ntree_limit:476, auc = 0.9714961, cost: 289.630069971s\n",
      "bagging_fraction=1.0 feature_fraction=0.5 , best_ntree_limit:441, auc = 0.9717915, cost: 58.7059049606s\n",
      "bagging_fraction=1.0 feature_fraction=0.6 , best_ntree_limit:494, auc = 0.9713985, cost: 66.3529839516s\n",
      "bagging_fraction=1.0 feature_fraction=0.7 , best_ntree_limit:436, auc = 0.9716777, cost: 63.4529578686s\n",
      "bagging_fraction=1.0 feature_fraction=0.8 , best_ntree_limit:400, auc = 0.9715962, cost: 62.238006115s\n",
      "bagging_fraction=1.0 feature_fraction=0.9 , best_ntree_limit:342, auc = 0.9711587, cost: 58.1756892204s\n",
      "bagging_fraction=1.0 feature_fraction=1.0 , best_ntree_limit:476, auc = 0.9714961, cost: 75.0526368618s\n",
      "===========best paramter: bagging_fraction=0.5 feature_fraction=0.5  auc=0.9717915===========\n"
     ]
    }
   ],
   "source": [
    "cv_paramters = {'bagging_fraction':common_num_range(0.5, 1.1, 0.1), 'feature_fraction':common_num_range(0.5,1.1,0.1)}\n",
    "model_cross_validate(lgbm_params, cv_paramters,dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Regularization Parameters: lambda_l1, lambda_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_l1=0 lambda_l2=0 , best_ntree_limit:823, auc = 0.9710004, cost: 93.9876971245s\n",
      "lambda_l1=0 lambda_l2=1 , best_ntree_limit:681, auc = 0.9717348, cost: 89.2005209923s\n",
      "lambda_l1=0 lambda_l2=10 , best_ntree_limit:310, auc = 0.9712283, cost: 49.6835539341s\n",
      "lambda_l1=0 lambda_l2=50 , best_ntree_limit:420, auc = 0.9711120, cost: 61.5471329689s\n",
      "lambda_l1=0 lambda_l2=100 , best_ntree_limit:416, auc = 0.9711464, cost: 60.1774940491s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bbd803df28f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcv_paramters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'lambda_l1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lambda_l2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_cross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgbm_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_paramters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-bdd2f8a27ad0>\u001b[0m in \u001b[0;36mmodel_cross_validate\u001b[0;34m(model_params, cv_param_dict, dtrain, cv_num_boost_round, early_stopping_rounds, cv_nfold, stratified)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         cv_result = lgbm.cv(model_params, dtrain, num_boost_round=cv_num_boost_round, stratified=stratified,\n\u001b[0;32m---> 21\u001b[0;31m                            nfold=cv_nfold, early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mbest_num_boost_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc-mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/lightgbm/engine.pyc\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks)\u001b[0m\n\u001b[1;32m    440\u001b[0m                                     \u001b[0mend_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agg_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/lightgbm/engine.pyc\u001b[0m in \u001b[0;36mhandlerFunction\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboosters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandlerFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/lightgbm/basic.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1414\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1415\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1416\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1417\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_paramters = {'lambda_l1':[0, 1, 10, 50, 100],'lambda_l2':[0, 1, 10, 50, 100]}\n",
    "model_cross_validate(lgbm_params,cv_paramters,dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Learning Rate and Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm_params['feature_fraction'] = 0.9\n",
    "lgbm_params['bagging_fraction'] = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.7,\n",
       " 'bagging_seed': 10,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'feature_fraction': 0.9,\n",
       " 'feature_fraction_seed': 10,\n",
       " 'lambda_l1': 0.5,\n",
       " 'lambda_l2': 0.5,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_bin': 255,\n",
       " 'metric': 'auc',\n",
       " 'min_child_weight': 1,\n",
       " 'min_split_gain': 0,\n",
       " 'min_sum_hessian_in_leaf': 0.1,\n",
       " 'num_leaves': 64,\n",
       " 'num_thread': -1,\n",
       " 'objective': 'binary',\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
